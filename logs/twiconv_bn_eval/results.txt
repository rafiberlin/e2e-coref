Evaluated 1/113 examples.
Evaluated 11/113 examples.
Evaluated 21/113 examples.
Evaluated 31/113 examples.
Evaluated 41/113 examples.
Evaluated 51/113 examples.
Evaluated 61/113 examples.
Evaluated 71/113 examples.
Evaluated 81/113 examples.
Evaluated 91/113 examples.
Evaluated 101/113 examples.
Evaluated 111/113 examples.
Predicted conll file: /tmp/tmpam8sjke1
Official result for muc
version: 8.01 /project/e2e-coref/conll-2012/scorer/v8.01/lib/CorScorer.pm

====== TOTALS =======
Identification of Mentions: Recall: (2587 / 3396) 76.17%        Precision: (2587 / 2921) 88.56% F1: 81.9%
--------------------------------------------------------------------------
Coreference: Recall: (1742 / 2474) 70.41%       Precision: (1742 / 2139) 81.43% F1: 75.52%
--------------------------------------------------------------------------

Official result for bcub
version: 8.01 /project/e2e-coref/conll-2012/scorer/v8.01/lib/CorScorer.pm

====== TOTALS =======
Identification of Mentions: Recall: (2587 / 3396) 76.17%        Precision: (2587 / 2921) 88.56% F1: 81.9%
--------------------------------------------------------------------------
Coreference: Recall: (2067.86099449929 / 3396) 60.89%   Precision: (2189.61255563368 / 2921) 74.96%     F1: 67.19%
--------------------------------------------------------------------------

Official result for ceafe
version: 8.01 /project/e2e-coref/conll-2012/scorer/v8.01/lib/CorScorer.pm

====== TOTALS =======
Identification of Mentions: Recall: (2587 / 3396) 76.17%        Precision: (2587 / 2921) 88.56% F1: 81.9%
--------------------------------------------------------------------------
Coreference: Recall: (562.038553037293 / 922) 60.95%    Precision: (562.038553037293 / 782) 71.87%      F1: 65.96%
--------------------------------------------------------------------------

Average F1 (conll): 69.56%
Average Recall (conll): 64.08%
Average Precision (conll): 76.09%
Average F1 (py): 69.54%
Average precision (py): 76.08%
Average recall (py): 64.05%